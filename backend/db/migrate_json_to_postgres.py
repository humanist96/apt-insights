"""
JSON to PostgreSQL ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

ëª¨ë“  JSON íŒŒì¼ì˜ ë°ì´í„°ë¥¼ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•©ë‹ˆë‹¤.
ì¤‘ë³µ ì œê±° ë° ë°ì´í„° ê²€ì¦ ê¸°ëŠ¥ í¬í•¨.
"""
import sys
from pathlib import Path
from typing import List, Dict, Tuple
from datetime import datetime
import argparse

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from tqdm import tqdm
from backend.data_loader import _load_from_json, remove_duplicates
from backend.db.session import get_session, init_db
from backend.db.repository import TransactionRepository
from backend.db.models import Transaction


def validate_data(items: List[Dict]) -> Tuple[List[Dict], List[Dict]]:
    """
    ë°ì´í„° ê²€ì¦

    Args:
        items: ì›ë³¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸

    Returns:
        (ìœ íš¨í•œ ë°ì´í„°, ë¬´íš¨í•œ ë°ì´í„°)
    """
    valid = []
    invalid = []

    for item in items:
        # í•„ìˆ˜ ì›ë³¸ í•„ë“œ ì²´í¬ (normalized fieldsëŠ” Transaction.from_dictì—ì„œ ìë™ ìƒì„±ë¨)
        # ìµœì†Œí•œ API íƒ€ì…ê³¼ ê±°ë˜ ë‚ ì§œ ì •ë³´ê°€ ìˆì–´ì•¼ í•¨
        required_fields = ['_api_type', 'dealYear', 'dealMonth', 'dealDay']
        missing_fields = [f for f in required_fields if not item.get(f)]

        if missing_fields:
            item['_validation_error'] = f"Missing fields: {missing_fields}"
            invalid.append(item)
        else:
            valid.append(item)

    return valid, invalid


def generate_migration_report(
    total_json: int,
    total_after_dedup: int,
    valid: int,
    invalid: int,
    db_stats: Dict,
    duration_seconds: float
) -> str:
    """
    ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬í¬íŠ¸ ìƒì„±

    Returns:
        ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¦¬í¬íŠ¸
    """
    report = f"""
# JSON to PostgreSQL ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬í¬íŠ¸

**ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ì†Œìš” ì‹œê°„**: {duration_seconds:.2f}ì´ˆ

## 1. ë°ì´í„° ë¡œë“œ (JSON)

- ì›ë³¸ JSON ë ˆì½”ë“œ: **{total_json:,}ê°œ**
- ì¤‘ë³µ ì œê±° í›„: **{total_after_dedup:,}ê°œ** (ì¤‘ë³µ {total_json - total_after_dedup:,}ê°œ ì œê±°)

## 2. ë°ì´í„° ê²€ì¦

- ìœ íš¨í•œ ë ˆì½”ë“œ: **{valid:,}ê°œ** âœ…
- ë¬´íš¨í•œ ë ˆì½”ë“œ: **{invalid:,}ê°œ** âŒ

## 3. ë°ì´í„°ë² ì´ìŠ¤ ì‚½ì… ê²°ê³¼

- ì‚½ì… ì„±ê³µ: **{db_stats.get('inserted', 0):,}ê°œ**
- ì—…ë°ì´íŠ¸: **{db_stats.get('updated', 0):,}ê°œ**
- ì—ëŸ¬: **{db_stats.get('errors', 0):,}ê°œ**

## 4. ìµœì¢… í†µê³„

- ë°ì´í„°ë² ì´ìŠ¤ ì´ ë ˆì½”ë“œ: **{db_stats.get('total_in_db', 0):,}ê°œ**
- ì„±ê³µë¥ : **{(db_stats.get('inserted', 0) / valid * 100 if valid > 0 else 0):.2f}%**

## 5. ê²€ì¦

{'âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µ' if db_stats.get('inserted', 0) == valid else 'âš ï¸  ì¼ë¶€ ë°ì´í„° ëˆ„ë½'}

---
*Generated by migrate_json_to_postgres.py*
"""
    return report


def main():
    """ë©”ì¸ ë§ˆì´ê·¸ë ˆì´ì…˜ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='JSON to PostgreSQL ë§ˆì´ê·¸ë ˆì´ì…˜')
    parser.add_argument('--dry-run', action='store_true', help='ì‹¤ì œ ì‚½ì… ì—†ì´ ê²€ì¦ë§Œ ìˆ˜í–‰')
    parser.add_argument('--batch-size', type=int, default=1000, help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 1000)')
    parser.add_argument('--on-conflict', choices=['ignore', 'update'], default='ignore',
                        help='ì¤‘ë³µ ì‹œ ì²˜ë¦¬ (ê¸°ë³¸ê°’: ignore)')
    args = parser.parse_args()

    print("=" * 80)
    print("JSON to PostgreSQL ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
    print("=" * 80)

    start_time = datetime.now()

    # 1. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    print("\n[1/6] ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”...")
    if not args.dry_run:
        init_db()
        print("âœ… í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
    else:
        print("â„¹ï¸  DRY-RUN ëª¨ë“œ: í…Œì´ë¸” ìƒì„± ìŠ¤í‚µ")

    # 2. JSON ë°ì´í„° ë¡œë“œ
    print("\n[2/6] JSON íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ...")
    items, debug_info = _load_from_json(None, debug=True)
    print(f"âœ… {len(items):,}ê°œ ë ˆì½”ë“œ ë¡œë“œ ì™„ë£Œ")
    print(f"   - ì„±ê³µ íŒŒì¼: {len(debug_info.get('successful_files', []))}ê°œ")
    print(f"   - ì‹¤íŒ¨ íŒŒì¼: {len(debug_info.get('failed_files', []))}ê°œ")

    if not items:
        print("âŒ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    total_json = len(items)

    # 3. ì¤‘ë³µ ì œê±°
    print("\n[3/6] ì¤‘ë³µ ì œê±°...")
    items = remove_duplicates(items)
    total_after_dedup = len(items)
    print(f"âœ… {total_after_dedup:,}ê°œ ìœ ë‹ˆí¬ ë ˆì½”ë“œ (ì¤‘ë³µ {total_json - total_after_dedup:,}ê°œ ì œê±°)")

    # 4. ë°ì´í„° ê²€ì¦
    print("\n[4/6] ë°ì´í„° ê²€ì¦...")
    valid_items, invalid_items = validate_data(items)
    print(f"âœ… ìœ íš¨: {len(valid_items):,}ê°œ")
    if invalid_items:
        print(f"âš ï¸  ë¬´íš¨: {len(invalid_items):,}ê°œ")
        for item in invalid_items[:5]:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            print(f"   - {item.get('_validation_error', 'Unknown error')}")

    # 5. ë°ì´í„°ë² ì´ìŠ¤ ì‚½ì…
    print(f"\n[5/6] PostgreSQL ì‚½ì… ({args.on_conflict} ëª¨ë“œ)...")
    db_stats = {'inserted': 0, 'updated': 0, 'errors': 0}

    if not args.dry_run:
        with get_session() as session:
            repository = TransactionRepository(session)

            # ì§„í–‰ë¥  í‘œì‹œ
            with tqdm(total=len(valid_items), desc="ì‚½ì… ì¤‘", unit="ë ˆì½”ë“œ") as pbar:
                batch_size = args.batch_size
                for i in range(0, len(valid_items), batch_size):
                    batch = valid_items[i:i + batch_size]
                    batch_stats = repository.bulk_insert_transactions(
                        batch,
                        batch_size=batch_size,
                        on_conflict=args.on_conflict
                    )
                    db_stats['inserted'] += batch_stats['inserted']
                    db_stats['updated'] += batch_stats['updated']
                    db_stats['errors'] += batch_stats['errors']
                    pbar.update(len(batch))

        print(f"âœ… ì‚½ì… ì™„ë£Œ: {db_stats['inserted']:,}ê°œ")
        if db_stats['updated'] > 0:
            print(f"   ì—…ë°ì´íŠ¸: {db_stats['updated']:,}ê°œ")
        if db_stats['errors'] > 0:
            print(f"   ì—ëŸ¬: {db_stats['errors']:,}ê°œ")

        # ìµœì¢… DB í†µê³„
        with get_session() as session:
            repository = TransactionRepository(session)
            final_stats = repository.get_statistics()
            db_stats['total_in_db'] = final_stats['total']
            print(f"\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì´ ë ˆì½”ë“œ: {final_stats['total']:,}ê°œ")
            print(f"   API íƒ€ì…ë³„:")
            for api_type, count in final_stats['by_type'].items():
                print(f"   - {api_type}: {count:,}ê°œ")

    else:
        print("â„¹ï¸  DRY-RUN ëª¨ë“œ: ì‹¤ì œ ì‚½ì… ìŠ¤í‚µ")
        db_stats['inserted'] = len(valid_items)
        db_stats['total_in_db'] = len(valid_items)

    # 6. ë¦¬í¬íŠ¸ ìƒì„±
    print("\n[6/6] ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬í¬íŠ¸ ìƒì„±...")
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()

    report = generate_migration_report(
        total_json=total_json,
        total_after_dedup=total_after_dedup,
        valid=len(valid_items),
        invalid=len(invalid_items),
        db_stats=db_stats,
        duration_seconds=duration
    )

    # ë¦¬í¬íŠ¸ ì €ì¥
    report_path = Path(__file__).parent / f"migration_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    report_path.write_text(report, encoding='utf-8')
    print(f"âœ… ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")

    # ì½˜ì†” ì¶œë ¥
    print("\n" + "=" * 80)
    print(report)
    print("=" * 80)

    # ì„±ê³µ ì—¬ë¶€
    if db_stats['inserted'] == len(valid_items) and db_stats['errors'] == 0:
        print("\nğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µ!")
        return 0
    else:
        print("\nâš ï¸  ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ (ì¼ë¶€ ì—ëŸ¬ ë°œìƒ)")
        return 1


if __name__ == '__main__':
    sys.exit(main())
